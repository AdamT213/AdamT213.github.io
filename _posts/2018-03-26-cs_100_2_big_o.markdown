---
layout: post
title:      "CS 100.2: Big O"
date:       2018-03-26 19:46:09 +0000
permalink:  cs_100_2_big_o
---


Okay, so I know I said that in my next post I would cover linked lists and believe me, that will come next week. However, it has since become clear to me that it is pointless to study concepts like algorithms and data structures without first having a thorough grasp of the foundational idea on which they rely: Big O Notation. Today, I will cover Big O and its many applications throughout computer science. 

To begin with, Big O is essentially a mathematical concept. In fact, if you can remember back to college or high school algebra, it is very closely intertwined with the degree and end behavior of a function. Take, for example, the function f(x) = 3x^4 + 4x^3 + x^2 + 2x +5. You may recall that the degree of this function is 4, since this is the exponent of the leading term. As x becomes arbitrarily large, the x^4 term will dominate all other terms and determine the end behavior of the function. If you understand that, then you understand Big O. 

The other important thing to note about Big O is that it does not take into account constants. The leading coefficient, in this case 3, is, for our purposes, irrevelant as X approaches infinity, since, again, the effect that the degree of the function has on its end behavior will dwarf the effect of any term or coefficient. (If you want to better understand the mathematical basis for Big O, and for that matter, Big O in general, I highly recommend watching this video https://www.youtube.com/watch?v=ei-A_wy5Yxw&index=2&list=PL1BaGV1cIH4UhkL8a9bJGG356covJ76qN. It goes into the components of Big O, which are Big O, Big theta and Big Omega. It is not essential for our purposes to understand these concepts, but it will help you more fully grasp why Big O matters and how it relates to what we do as programmers. For now, suffice it to say that, in an academic context, Big O of some function provides a "lower bound" for the behavior of the function, Big Omega provides an "upper bound", and Big Theta sandwiches the function between these bounds. Also note that, when we talk about Big O in the real world, the idea most closely resembles the Big Theta spoken of in the video. All that said, if you have 50 minutes to invest in your career as a programmer, I cannot recommend strongly enough that you WATCH THE VIDEO!). 

Okay, you may be wondering, so Big O essentially determines the end behavior of a function. Why should we care? In computer science, Big O relates to the concept of asymptotic time and space complexity. Asymptotic means as the input size grows boundlessly, i.e., as it approaches infinity, and this is where Big O comes in. Say, for example, you have come up with two solutions to a problem in programming. Both work, but as I said in the previous post, and I cannot stress this enough: IT IS NOT ENOUGH FOR SOLUTIONS IN PROGRAMMING TO JUST "WORK". They must be optimal, or at least, closer to optimal than anybody else's solution. Okay, so you know that you need some means of evaluating the two solutions. But what does optimal really mean? It means that the asymptotic complexity of the function is the best it can be, or good enough that any improvement would be trivial. 

It is important to note that I said Big O applies to both the time and space that a particular function takes. While this is true, it is often best to first consider the time complexity of a function. It is then important to note that a function does not only have one time complexity. Depending on the nature of the input, for example, a given algorithm can take vastly different amounts of time to run. Broadly speaking, we can have the "best case" time complexity, the "average case" time complexity, and the "worst case" time complexity. As programmers, we almost never consider the best case time complexity, since, in the best case scenario, all algorithms and data structures perform a job impressively well. The average case is important, but it can often be difficult to calculate and agree upon, so as beginners, we tend not to focus on it in our analysis. This leaves the worst case time complexity, which, you could say, is the most widely-used metric for evaluating a piece of code. After all, if you know how well a function performs in the worst case, then you know whether that function is worth using for a particular application.  For example, if on average it took 1 second to log into facebook, but once every 19 times or so it took 30 seconds, you would probably think that facebook was a poorly made site and would look elsewhere for your social media jollies. 

Next, we must consider space complexity, i.e., the amount of memory that a program will require. Again, we are only interested in the "Big O" of space complexity, or how this number changes as the input size grows asymptotically. Again, it is acceptable as a beginner to consider space complexity an afterthought when evaluating a program. For now, think of worst case time complexity as the main feature of Big O analysis, and think of average case time complexity and space complexity as tiebreakers, should two solutions prove to be the same in terms of worst case time. 

Okay, enough theory. Let's dive into some examples to help drive the point home. Throughout Big O analyses, there are some common values that will come up again and again. It is not recommended to memorize them, but instead, to understand how they are derived. First, let's look at what is considered a very good Big O complexity, O(1).  A time complexity of O(1) means that a process occurs in "constant time", i.e., that the time it takes does not depend on the size of the input. For example, consider looking up an index in an array. Whether the array is of length 1000 or length 10, finding the element at index 9 will take the same amount of time, and for this reason, looking up values in an array is considered a very efficient process. It is easy to understand that a program cannot be more efficient than O(1).

Another common Big O complexity is O(n). This means that a process occurs in "linear time", which means exactly what you would think given its mathematical definition. The time that the process takes grows proportionally to the input size. Take, for example, adding an element to the beginning of an array. In order to do so, all other elements must be pushed back by one index, which means, effectively, that each element in the array must be "touched" once during this procedure. Clearly, this means that the longer the array, the longer this will take. This may still seem like an efficient process, and indeed, for some operations, an O(n) algorithm or data structure would be a dream come true. However, for simply adding an item at the beginning of a collection, linked lists, which we will discuss in more detail next week, are more efficient than arrays. 

Logarithms come up very frequently in Big O analysis, and it is important to understand why. For example O(log n) is a very common time complexity, and is the Big O of one of the most efficient and widely used searching algorithms, binary search. In binary search, finding an element is done by locating the median value in a sorted data structure, and comparing the value you are searching for to the median value. If the sought after value is smaller, the median becomes the new high value, and the midpoint of the resulting data structure, half the size of the original, becomes the new median. The exact opposite process occurs if the sought after value is greater than the median, and this process repeats recursively  until the value is either located or determined not to be present. It is easy to see why this process is logarithmic, and in particular, log base 2, since it will occur at most log base 2 of n times for some input size n. Since so many computer operations are binary, when we say log, we almost always mean log base 2. This however, is irrelevant, since according to the laws of logarithms, log base a of x and log base b of x always differ at most by a constant c, and constants do not matter in Big O analysis. 

When first learning to calculate the Big O of  a function, there can be a strong temptation to simply guess based on the common values. You must resist this urge, and instead, reason through the code. For example, in a function with nested loops, the big O will be exponential based on the number of nested loops. For example, if you have a program that iterates over two different arrays of length n with nested for loops, the Big O will O(n^2), since, for each item in array 1, it must perform an action in both array 1 and array 2. If, however, the loops are not nested, but are instead one, then the other, the operation will be just O(n). This may seem intuitively difficult to grasp, but if two loops are run side by side, the whole process will take O(2n). Since constants are irrelevant, this simplifies to O(n). Some examples are considerably tougher than this, but with time and practice, calculating Big O becomes second nature. 

I hope this helps you come to a better basic understanding of time and space complexity. Watch the video, it will truly help elevate your understanding far more. Beyond that, I have decided that I am going to start ending these posts with a cheesy, inspirational quote, since autodidacting computer science is a grueling task that warrants some extra motivation. Plus, I like cheesy, inspirational quotes. So without further ado, today's words of wisdom come to us from H.G Wells: 
"The only true measure of success is the ratio between what we might have done and what we might have been on the one hand, and the thing we have made and the things we have made of ourselves on the other" 

Til next time!


